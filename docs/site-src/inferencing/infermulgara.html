@@includeTop@@
 
    <title>Mulgara &#124; Semantic Store - Inferencing and Mulgara</title>
    <meta name="keywords" content="Inferencing, mulgara project, metadata, metastore, metadatabase, datastore, database, scaleable, scalable, transaction, java, open source, rdf, resource description framework" />
	
@@includeMiddle@@		
   
<!-- INNER PAGE NAVIGATION STARTS HERE -->
<div id="navPage">
		<a href="#top">Top</a>	&#124;
    
		<a href="/inferencing/infermulgara.html#o2726">Models Required</a> &#124; 
		<a href="/inferencing/infermulgara.html#o2730">An Example</a>

</div>
<!-- INNER PAGE NAVIGATION ENDS HERE -->



<!-- PAGE CONTENT STARTS HERE -->
<div id="content" class="inOut">  
<a name="textonlynav"></a>	  
	





<!--
<p><a href="/inferencing/infersummery.html"><img src="previous.gif" alt="Previous Topic" height="25px" width="23px" vspace="2" hspace="2" align="bottom" border="0" /></a></p>

<p><a href="/inferencing/owl.html"><img src="next.gif" alt="Next Topic" height="25px" width="23px" vspace="2" hspace="2" align="bottom" border="0" /></a></p> 

<p class="relatedheading">See Also</p>
<p class="relateditem"><a href="/inferencing/index.html">Inferencing</a></p>
<p class="relateditem"><a href="/inferencing/inferintro.html">Introduction to Inferencing</a></p>
<p class="relateditem"><a href="/inferencing/owl.html">OWL-Lite Operations Using iTQL</a></p>
<p class="relateditem"><a href="/inferencing/sofa.html">SOFA</a></p>
<p class="relateditem"><a href="/inferencing/inferexample.html">Inferencing Examples Using SOFA and iTQL</a></p>

 -->




<h2>Inferencing and Mulgara</h2>

<p>Inferencing is a process of producing new RDF statements from a set of existing ones. This is implemented in Mulgara using a base model of RDF statements, applying a set of rules, then storing the newly generated statements in a new model.</p>

<p>We can demonstrate this by defining a small data model and a set of rules. The data model consists of the following statements:</p>

<p class="commandtext">[ (leftHand, partOf, body)<br />
  (rightHand, partOf, body)<br />
  (leftIndexFinger, partOf, leftHand)<br />
  (leftHand, is, left)<br />
  (rightHand, is, right)<br />
  (leftHand, hasName, &quot;left hand&quot;)<br />
  (rightHand, hasName, &quot;right hand&quot;)<br />
  (leftIndexFinger, hasName, &quot;left index finger&quot;) ]</p>

<p>The rules are defined as follows:</p>
<ol><li>Create a hierarchy of <code>partOf</code> statements where properties are inherited. That is:<ul><li><code>if (x, partOf, y) and ( y, partOf, z) then (x, partOf z)</code></li><li><code>if (a, is, b) then (z, is, b)</code></li><li>When Rule 1 is executed call Rule 2</li></ul></li><li>Create a new statement such that, <code>if (x, is, y) then ( x, hasProperty, y)</code></li></ol>
<p>The statements in the new model generated by these rules are as follows:</p>

<p class="commandtext">[ (leftIndexFinger, partOf, body)<br />
  (leftIndexFinger, is, left)<br />
  (leftIndexFinger, hasProperty, left)<br />
  (leftHand, hasProperty, left)<br />
  (rightHand, hasProperty, right) ]</p>

<div class="anchor"><a name="o2726">&nbsp;</a></div>
<h3>Models Required</h3>

<p>Inferencing requires ways of grouping statements into differing types of models, allowing the system to differentiate and apply appropriate operations on them. Also, models have configuration and other statements made about them in the system model. This allows the system to further control how models are treated during inferencing and other operations.</p>

<p>Initially, there are three model types:</p>
<ol><li>Base models</li><li>Schema models (RDFS and OWL)</li><li>Inference models</li></ol>
<div class="anchor"><a name="o2727">&nbsp;</a></div>
<h4>Base Model</h4>

<p>Base models are the current type of Mulgara model used for storing RDF statements.</p>
<div class="anchor"><a name="o2728">&nbsp;</a></div>
<h4>Schema Model</h4>

<p>A schema model is either an OWL or RDFS typed schema model. OWL and RDFS are predefined sets of rules, and when and how to apply them when certain statements are encountered. There are three versions of OWL:</p>
<ol><li>OWL Lite</li><li>OWL DL</li><li>OWL Full</li></ol>
<p>The difference between the three versions is the number of and complexity of the rules.</p>

<p>The type of configuration to apply to schema models defines how the rules are applied. This includes which combination of rules and base statements generate an inference model, as well as which rules are processed ahead of time (forward chaining) or at query time (backward chaining).</p>

<p>Schema models usually have a very a small number of statements in comparison to the base models. A schema model, or collection of models, is tied to one or more base models. The system allows one or more schemas models to be applied to one or more collections of base models to generate one or more sets of new inferred models.</p>

<p>It is also important to allow classes to be used as instances. A class is a definition of the properties of an object. An instance is a particular concrete version of a type of class. An analogy in Java is a class is an <em>interface</em> and an object created at run-time with a <em>new</em> statement is an instance. In OWL this view of whether something is an instance or a class can change depending on how they are used. If a user is creating an ontology, from their point of view the schema model contains a set of instances to be manipulated. To the inferencing system, the schema model is a set of classes to be used by rules to generate new statements.</p>
<div class="anchor"><a name="o2729">&nbsp;</a></div>
<h4>Inference Model</h4>

<p>An inference model contains the result of executing the rules defined in the schema model against the data stored in the base models. Usually, inference models are not directly queried by the user but are queried in conjunction with the base model or models.</p>
<div class="anchor"><a name="o3141">&nbsp;</a></div>


<p>Having an inference model separate from the other models allows the inferred model to be modified at any time. If the base models or schema models change only the inference model needs to change. To provide improved granularity and maximum control over inferred statements, these inferred statements can be composed of several models aggregated together. This provides a way to retain a map of inferred statements against the original data, schemas and rules that were applied. When the parts of the schema or original data changes only the minimal set of statements related to that change is removed and then re-inferred.</p>

<p>These mappings, of inferred statements, rules and base facts, take the form of annotations and describe the set of statements and set of rules that generated them. A rule is further constrained by expressing a subset of the original statements using an iTQL<sup>TM</sup> query.</p>
<div class="anchor"><a name="o2730">&nbsp;</a></div>
<h3>An Example</h3>

<p>Take the example where you have two models:</p>
<ol><li>A base model of facts</li><li>An RDFS schema model</li></ol>
<p>The administrator or inference optimizer determines that the RDFS rule <code>subClassOf</code> should be fully inferred and the results placed in an inferred model of its own. The remaining RDFS rules are fully inferred and and their results placed in a second inferred model.</p>

<p>This is expressed using the following set of statements:</p>

<p class="commandtext">[ ( &lt;baseModel1&gt;, &lt;modelType&gt;, &lt;model&gt; )<br />
  ( &lt;rdfsSchemaModel1&gt;, &lt;modelType&gt;, &lt;rdfs&gt; )<br />
  ( &lt;inferenceModel1&gt;, &lt;modelType&gt;, &lt;inference&gt; )<br />
  ( &lt;inferenceModel2&gt;, &lt;modelType&gt;, &lt;inference&gt; )<br />
  ( &lt;rdfs:subClassOf&gt;, &lt;inferenceType&gt;, &lt;forward&gt; )<br />
  ( &lt;rdfs:domain&gt;, &lt;inferenceType&gt;, &lt;forward&gt; )<br />
  ( &lt;inferenceModel1&gt;, &lt;includesRule&gt;, &lt;rdfs:subClassOf&gt; )<br />
  ( &lt;inferenceModel2&gt;, &lt;includesRule&gt;, &lt;rdfs:domain&gt; )<br />
  ...<br />
]</p>
<div class="anchor"><a name="o3142">&nbsp;</a></div>


<p>Any user queries are now performed against the union of three models:</p>
<ol><li>Base facts (<code>baseModel1</code>)</li><li>The <code>subClassOf</code> inference model (<code>inferenceModel1</code>)</li><li>The remaining RDFS rules (<code>inferenceModel2</code>)</li></ol>
<div class="anchor"><a name="o3143">&nbsp;</a></div>


<p>In this way each inference model handles different groups of inferred statements. By splitting the two inference models between <code>subClassOf</code> and the other RDFS rules we are saying that they are computationally equivalent. This is determinate on the following factors:</p>
<ul><li>The rules to apply</li><li>The schema</li><li>The original data</li><li>How often and what type of changes occur to the schema or original data</li></ul>
<div class="anchor"><a name="o3144">&nbsp;</a></div>


<p>A performance enhancement that a user or the system can determine is when certain queries are leading to continual dropping and re-inferencing. Alternatively, continually inferring the same set of statements at query time would benefit from caching these statements in an inference model.</p>

			
    





</div>
<!-- PAGE CONTENT ENDS HERE -->

@@includeBottom@@


